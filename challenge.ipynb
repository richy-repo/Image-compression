{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some important notes: \n",
    "This challenge is more about data processing, and machine learning techniques. The prepared data could be used to train machine learning or AI models to determine whether a parasite has cancer based on some \"factors/predictors\". I had a strong background in Machine learning and AI, a few years ago. When I had my undergraduate degree, in statiscis and comoputer science, my focus was on AI and machine learning. After the graduation and my master degree, I shifted my focus more to web development, working with cloud, frontend technologies and backend technologies, such as react, angular, node, python, fastapi, express, java spring boot, docker, microservice, etc. So I am no longer proficient in working with data processing and train models. But I did this question as best as I could. \n",
    "\n",
    "Therefore, this kind of challenge is no longer my strength at the moment of this challenge. But I am willing to do some review and refresh my memory if I could be considered as candidates for this type of role. Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Image by microscope: One representation is that I can use a bitmap with run length encoding. I initially intended to represent images as 2-d array in python, and I can utilize the GPU's parallel processing in pytorch for further analysis easily. But I notice that the question's requirement is to use as less storage/memory as possible. Therefore, a bitmap with run length encoding would more closely align with the requrements. \n",
    "\n",
    "Since the large amount of consecutive bits are of the same color(white or black), we will use 33 bits to store each run. For example, the 32 bits stores the length of the run, and the last bit stores the color (0 for white, 1 for black).\n",
    "\n",
    "In the worst case, there are 10 billion runs(color alternates). Then there would be 1000000000 * 33 bits. This would be worse than using two d array. But only by a constant factor which is 33. In big O notation, the storage is O(n), suppose n is the number of bits in two d array, which is linear in the worse case for both 2d array representation, and bitmap representation. To translate to bytes, you will simply divde that number by 4\n",
    "\n",
    "But in practice, this representation would be better. Since the situation is likely that in a single row of the 2d array representation, there are only constant number alternations of colors(because the blog is grouped together), then the storage becomes\n",
    "O(log(n)), which would be better than the two d array\n",
    "\n",
    "I would represent dye image in the same way, because given the situation of this challenge, the dye image is also binary(whether the dye is lit or not). Bitmap is great for binary representations. \n",
    "\n",
    "I also reserached if there are intensities of the dye involved, we will use other representations such as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qestion 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasite Bitmap Size: 125000 bytes\n",
      "Dye Bitmap Size: 125000 bytes\n"
     ]
    }
   ],
   "source": [
    "# %pip install numpy opencv-python matplotlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_parasite_image(width, height, min_blob_size=0.25):\n",
    "    \"\"\"\n",
    "    Generate a simulated microscope image with binary blobs representing parasites.\n",
    "    \"\"\"\n",
    "    image = np.zeros((height, width), dtype=np.uint8)\n",
    "    num_blobs = np.random.randint(1, 5)  # Randomly choose the number of blobs\n",
    "    \n",
    "    for _ in range(num_blobs):\n",
    "        # Randomly choose the center and size of the blob\n",
    "        center = (np.random.randint(width), np.random.randint(height))\n",
    "        radius = np.random.randint(int(min_blob_size * min(width, height)), int(0.5 * min(width, height)))\n",
    "        cv2.circle(image, center, radius, 1, -1)  # Draw the blob\n",
    "    \n",
    "    return image\n",
    "\n",
    "def generate_dye_image(parasite_image, dye_leakage_prob=0.01):\n",
    "    \"\"\"\n",
    "    Generate a simulated dye sensor image based on the given parasite image.\n",
    "    \"\"\"\n",
    "    height, width = parasite_image.shape\n",
    "    dye_image = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    # Add dye within the parasites\n",
    "    dye_image[parasite_image == 1] = 1\n",
    "    \n",
    "    # Simulate dye leakage\n",
    "    leakage = np.random.rand(height, width) < dye_leakage_prob\n",
    "    dye_image[leakage] = 1\n",
    "    \n",
    "    return dye_image\n",
    "\n",
    "def create_bitmap(image_array):\n",
    "    \"\"\"\n",
    "    Create a bitmap from a binary image array.\n",
    "    \"\"\"\n",
    "    binary_image = (image_array > 0).astype(np.uint8)\n",
    "    bit_packed_image = np.packbits(binary_image)\n",
    "    return bit_packed_image\n",
    "\n",
    "def decode_bitmap(bit_packed_image, width, height):\n",
    "    \"\"\"\n",
    "    Decode a bitmap back to a binary image array.\n",
    "    \"\"\"\n",
    "    binary_image = np.unpackbits(bit_packed_image)\n",
    "    image_array = binary_image[:width * height].reshape((height, width))\n",
    "    return image_array\n",
    "\n",
    "# Parameters\n",
    "width, height = 1000, 1000 # I can only run for 1000. I will run out of memory if I do 100000\n",
    "\n",
    "# Generate simulated images\n",
    "parasite_image = generate_parasite_image(width, height)\n",
    "dye_image = generate_dye_image(parasite_image)\n",
    "\n",
    "# Convert to bitmap\n",
    "parasite_bitmap = create_bitmap(parasite_image)\n",
    "dye_bitmap = create_bitmap(dye_image)\n",
    "\n",
    "# Decode bitmap to verify\n",
    "decoded_parasite_image = decode_bitmap(parasite_bitmap, width, height)\n",
    "decoded_dye_image = decode_bitmap(dye_bitmap, width, height)\n",
    "\n",
    "\n",
    "print(f\"Parasite Bitmap Size: {len(parasite_bitmap)} bytes\")\n",
    "print(f\"Dye Bitmap Size: {len(dye_bitmap)} bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasite has cancer: True\n"
     ]
    }
   ],
   "source": [
    "def has_cancer(parasite_bitmap, dye_bitmap, width, height, cancer_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Determine if a parasite has cancer based on the amount of dye present.\n",
    "    Args:\n",
    "    - parasite_bitmap: Bit-packed binary image of the parasite.\n",
    "    - dye_bitmap: Bit-packed binary image of the dye presence.\n",
    "    - width: Width of the image.\n",
    "    - height: Height of the image.\n",
    "    - cancer_threshold: Threshold ratio of dye area to parasite area to classify as cancer.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the parasite has cancer, False otherwise.\n",
    "    \"\"\"\n",
    "    # Decode the bitmaps back to binary images for processing\n",
    "    parasite_image = decode_bitmap(parasite_bitmap, width, height)\n",
    "    dye_image = decode_bitmap(dye_bitmap, width, height)\n",
    "    \n",
    "    # Calculate the total area of the parasite\n",
    "    parasite_area = np.sum(parasite_image)\n",
    "    \n",
    "    # Calculate the area of dye within the parasite\n",
    "    dye_within_parasite = np.sum((parasite_image == 1) & (dye_image == 1))\n",
    "    \n",
    "    # Determine if the dye area exceeds the threshold\n",
    "    if dye_within_parasite / parasite_area > cancer_threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "cancer_status = has_cancer(parasite_bitmap, dye_bitmap, width, height)\n",
    "print(f\"Parasite has cancer: {cancer_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quesiton 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parasite has cancer: True\n"
     ]
    }
   ],
   "source": [
    "# Qestion 4\n",
    "def count_bits(bit_packed_image):\n",
    "    return np.sum(np.unpackbits(bit_packed_image))\n",
    "\n",
    "def decode_bitmap_subset(bit_packed_image, start, length):\n",
    "    \"\"\"\n",
    "    Decode a subset of a bitmap back to a binary image array.\n",
    "    \"\"\"\n",
    "    binary_image = np.unpackbits(bit_packed_image[start:start + length])\n",
    "    return binary_image\n",
    "\n",
    "def has_cancer_new(parasite_bitmap, dye_bitmap, width, height, cancer_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Determine if a parasite has cancer based on the amount of dye present.\n",
    "    Args:\n",
    "    - parasite_bitmap: Bit-packed binary image of the parasite.\n",
    "    - dye_bitmap: Bit-packed binary image of the dye presence.\n",
    "    - width: Width of the image.\n",
    "    - height: Height of the image.\n",
    "    - cancer_threshold: Threshold ratio of dye area to parasite area to classify as cancer.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the parasite has cancer, False otherwise.\n",
    "    \"\"\"\n",
    "    # Calculate the total area of the parasite by counting set bits\n",
    "    parasite_area = count_bits(parasite_bitmap)\n",
    "    \n",
    "    # Efficiently process the bitmaps in chunks to minimize memory usage\n",
    "    dye_within_parasite = 0\n",
    "    chunk_size = 1024  # Adjust this size based on available memory and performance\n",
    "    \n",
    "    num_chunks = len(parasite_bitmap) // chunk_size + (1 if len(parasite_bitmap) % chunk_size else 0)\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        length = min(chunk_size, len(parasite_bitmap) - start)\n",
    "        parasite_chunk = decode_bitmap_subset(parasite_bitmap, start, length)\n",
    "        dye_chunk = decode_bitmap_subset(dye_bitmap, start, length)\n",
    "        \n",
    "        dye_within_parasite += np.sum(parasite_chunk & dye_chunk)\n",
    "    \n",
    "    # Determine if the dye area exceeds the threshold\n",
    "    return dye_within_parasite / parasite_area > cancer_threshold\n",
    "\n",
    "cancer_status = has_cancer_new(parasite_bitmap, dye_bitmap, width, height)\n",
    "print(f\"Parasite has cancer: {cancer_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can avoid decoding the entire images by using chunks. We decode images by chunks and process by chunks, so when the threshold might be reached in the middle of the loop, then we avoid processing the rest, improving the speed. It also helps us save memory. \n",
    "\n",
    "I am running this on my local computer. Normally, I would run it in cloud env such as google colab, which can utilize GPU for extrememly fast processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could not come up with effective compression for this question, so I used both claud ai and chatgpt for an answer\n",
    "\n",
    "Based on my inqueries, Quadtree compression could be an answer. \n",
    "\n",
    "My understanding is that we represent the image in tree structure. Each node represent a group of bits with the value. We divide the square image into four quads, and keep diving until all bits in a quads are of the same value. Then such quad becomes a leaf. This could be an effective representation of the images besides the bitmap. \n",
    "\n",
    "But given the setting of this challenge, I belive quadtree does not necessarily produce a better run time/storage saving. \n",
    "\n",
    "I am using a laptop, and I got kernel error when I tried to generate images of 100000*100000. I believe the memory runs out. I believe it could be feasible to run the code in the cloud. I had experience using google colab before. When I trained machine learning model before and turned large neural network, I typically run the cloud using google colab and run on the GPU. When budget is sufficent, upgrading the hardware might be the most effective approach than dealing with compression techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "\n",
    "Tools I used for this challenge: \n",
    "\n",
    "Google(searching)\n",
    "Chatgpt(explaining the data structure, such as bitmap)\n",
    "\n",
    "I am good at writing prompts to the LLM, and ask for answers to my questions in my daily development task, and this can greatly increase my efficiency.\n",
    "\n",
    "I used chatgpt for the API of the libraries, such as ny functions, and some nuances.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
